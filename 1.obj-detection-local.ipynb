{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20337077-8a1d-46a8-8f00-622e316e3fe9",
   "metadata": {},
   "source": [
    "# AutoGluon Object Detection Tutorial\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "SageMaker Ground Truth로 레이블링 수행 완료 후 output.manifest를 로컬로 복사\n",
    "\n",
    "![sagemaker-gt](./script/sagemaker-gt.png)\n",
    "\n",
    "### References\n",
    "- AutoGluon Multimodal - Quick Start: https://auto.gluon.ai/stable/tutorials/multimodal/multimodal_prediction/multimodal-quick-start.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1819f7a-8199-46a7-9fad-8fc8b02e927a",
   "metadata": {},
   "source": [
    "### Download dataset\n",
    "\n",
    "You need to prepare your onw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9174484-71d0-487e-8ec6-a1520f4c52cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task = 'objdetection-pikachu'\n",
    "!rm *.json\n",
    "!rm -rf AutogluonModels tmp\n",
    "!rm -rf {task} && mkdir -p {task}\n",
    "!curl -L \"https://universe.roboflow.com/ds/xZJGldQLjS?key=B56tyPNKRM\" > roboflow.zip; unzip -q roboflow.zip -d {task}/images; rm roboflow.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aef7f84-5e87-422d-a6ea-46f84723d4c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Directory\n",
    "AutoGluon MultiModalPredictor의 Object Detection은 아래와 같은 디렉토리로 설정하는 것을 추천\n",
    "```\n",
    "├── [YOUR-TASK-DIR]\n",
    "│   ├── annotations: coco 포맷의 json annotation 파일이 위치한 경로\n",
    "│   └── images: raw 이미지 경로\n",
    "```\n",
    "\n",
    "본 샘플 코드의 예시는 아래와 같다.\n",
    "```\n",
    "├── objdetection-pikachu\n",
    "│   ├── annotations\n",
    "│   └── images\n",
    "│       ├── train\n",
    "│       ├── valid\n",
    "│       └── test\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9957cef6-5ee1-4b9d-9f7f-029a21ac32d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_path = f\"{task}/images\"\n",
    "annotations_path = f\"{task}/annotations\"\n",
    "!mkdir -p {annotations_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9248965-ca87-47f2-a9c6-75b81e8831f2",
   "metadata": {},
   "source": [
    "### Convert SageMaker Ground Truth manifest file to COCO-formatted json file\n",
    "- Step 1: SageMaker groundth truth의 manifest output 파일을 COCO 포맷으로 변환 (필요 시 utils.py 참조하여 수정할 것)\n",
    "- Step 2: COCO 포맷 파일을 데이터셋 폴더로 복사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843c98f7-4a1d-45d7-86c8-8aa0978a5985",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "from script.utils import convert_bbox_manifest, show_detection_result\n",
    "dataset_type = ['train', 'valid', 'test']\n",
    "json_path_dict = {}\n",
    "\n",
    "for d in dataset_type:\n",
    "    manifest_path = f\"manifest/pikachu-{d}-output.manifest\"\n",
    "    job_name = f\"objdetect-pikachu-gt-{d}-job\"\n",
    "    output_coco_json_path = f\"pikachu-{d}-coco.json\"\n",
    "    convert_bbox_manifest(manifest_path, job_name, output_coco_json_path, d)\n",
    "    json_path = f\"{annotations_path}/{output_coco_json_path}\"\n",
    "    shutil.copyfile(output_coco_json_path, json_path)\n",
    "    json_path_dict[d] = json_path\n",
    "\n",
    "train_path = json_path_dict['train']\n",
    "valid_path = json_path_dict['valid']\n",
    "test_path = json_path_dict['test']\n",
    "\n",
    "print(train_path, valid_path, test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e9c8b3-adf7-46d1-a594-77fbd37adea0",
   "metadata": {},
   "source": [
    "https://github.com/open-mmlab/mmdetection/tree/master/configs/yolox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a042c9-e941-491f-bfb5-c76c6ba90099",
   "metadata": {},
   "source": [
    "### Create MultiModalPredictor\n",
    "- `problem_type=\"object_detection\"` 으로 지정\n",
    "- `sample_data_path`는 객체(object)의 범주를 파악하기 위해 필요하며 COCO 포맷 json에 명시되어 있음\n",
    "- `model.mmdet_image.checkpoint_name`에서 객체 검출에 쓰일 모델 이름을 지정. 직접 모델을 지정하기 어렵다면 preset으로도 지정 가능 (예: `medium_quality, high_quality, best_quality`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9e3d49-8358-4458-a68a-1106ca74bd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.multimodal import MultiModalPredictor\n",
    "# Init predictor\n",
    "import uuid\n",
    "#presets = \"medium_quality\"\n",
    "checkpoint_name = \"yolox_l_8x8_300e_coco\"\n",
    "\n",
    "model_path = f\"./tmp/{uuid.uuid4().hex}-{task}-save\"\n",
    "predictor = MultiModalPredictor(\n",
    "    hyperparameters={\n",
    "        \"model.mmdet_image.checkpoint_name\": checkpoint_name,\n",
    "        \"optimization.val_metric\": \"map\",\n",
    "    },\n",
    "    problem_type=\"object_detection\",\n",
    "    sample_data_path=train_path,\n",
    "    #presets=presets,\n",
    "    path=model_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b48fb23-3214-4768-9d44-007608343854",
   "metadata": {},
   "source": [
    "### Training\n",
    "- More parameters: https://auto.gluon.ai/dev/tutorials/multimodal/advanced_topics/customization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f12333-61d6-4072-8e9f-bda4941d9fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "predictor.fit(\n",
    "    train_data=train_path,\n",
    "    tuning_data=valid_path,\n",
    "    hyperparameters={\n",
    "        \"optimization.learning_rate\": 3e-5,\n",
    "        \"env.per_gpu_batch_size\": 8,  # decrease it when model is large\n",
    "        \"optimization.max_epochs\": 10,  # max number of training epochs, note that we may early stop before this based on validation setting\n",
    "        \"optimization.check_val_every_n_epoch\": 2,  # Do k validation each 2 epochs\n",
    "        \"optimization.patience\": 3,  # Early stop after k consective validations are not the best\n",
    "    },\n",
    ")  # Fit\n",
    "end = time.time()\n",
    "print(\"This finetuning takes %.2f seconds.\" % (end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2211eab9-3cbd-4738-abdb-49905885141f",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ade0cc7-9dae-421a-886b-785b313c7216",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.evaluate(valid_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d652e1e0-9521-4d10-b510-8ae4f7d9e1cf",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ae3e68-955a-4a6a-af7f-066fe375ec55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315f8a36-f9e1-431a-9e29-6196c36fcfb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "test_path =f\"{task}/images/test\" \n",
    "\n",
    "test_files = glob(f'{test_path}/*.jpg') + glob(f'{test_path}/*.jpeg') + glob(f'{test_path}/*.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b763490a-294a-4485-842d-075517df3579",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c287ac3c-f4b7-47a2-9e49-f066ae644d95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "test_path = f\"{task}/images/test\" \n",
    "test_files = glob(f'{test_path}/*.jpg') + glob(f'{test_path}/*.jpeg') + glob(f'{test_path}/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeae2f0a-2d07-45a0-93c1-97871eb5aac6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_idx = 0\n",
    "img_path = test_files[test_idx]\n",
    "img_result = predictor.predict(img_path).iloc[0]\n",
    "print(img_result)\n",
    "show_detection_result(img_path, img_result, 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
